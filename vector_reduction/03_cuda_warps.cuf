
attributes(global) subroutine vector_reduction_kernel(values, n, result)
    implicit none
    integer, parameter :: int64 = selected_int_kind(18)
    integer, parameter :: int8 = selected_int_kind(2)
    integer, intent(in), value :: n
    integer(kind = int8), dimension(n), intent(in) :: values
    integer(kind = int64), intent(out) :: result
    
    integer(kind = int64), shared :: partial_sum(32)
    integer :: tmp, idx, warpid, laneid
    idx = (blockidx%x - 1) * blockdim%x + threadidx%x
    warpid = (threadIdx%x - 1) / warpsize + 1
    laneid = mod((threadIdx%x - 1),  warpsize) + 1
    if(laneid == 1) partial_sum(warpid) = 0
    call syncthreads()
    if(idx <= n) tmp = atomicAdd(partial_sum(warpid), values(idx))
    call syncthreads()
    if(laneid == 1 .and. warpid > 1) tmp = atomicAdd(partial_sum(1), partial_sum(warpid))
    call syncthreads()
    if(threadIdx%x == 1) tmp = atomicAdd(result, partial_sum(1))
end subroutine vector_reduction_kernel


subroutine cuda_check_error(err)
    use cudafor
    implicit none
    integer :: err
    if (err /= cudaSuccess) then
        print *, "CUDA ERROR: ", cudaGetErrorString(err)
        stop
    end if
end subroutine cuda_check_error


program vector_reduction
    use cudafor
    implicit none
    integer, parameter :: n = 1e9, n_threads = 1024, int64 = selected_int_kind(18)
    integer, parameter :: int8 = selected_int_kind(2)
    integer(kind = int8), dimension(:), allocatable :: values
    integer(kind = int8), dimension(:), allocatable, device :: dev_values
    integer(kind = int64), device :: dev_result
    integer :: n_blocks, i
    integer(kind = int64) :: correct_result, gpu_result
    real :: tmp, elapsed
    type(cudaEvent) :: start, stop
    ! allocate on main memory (CPU)
    allocate(values(n), dev_values(n))
    dev_result = 0
    correct_result = 0
    ! initialize array on CPU with random value
    do i = 1, n
        call random_number(tmp)
        values(i) = mod(i, 128)
        correct_result = correct_result + values(i)
    end do
    call cuda_check_error(cudaEventCreate(start))
    call cuda_check_error(cudaEventCreate(stop))
    ! copy data on GPU
    dev_values = values
    n_blocks = (n + n_threads - 1) / n_threads
    print *, "launching kernel.."
    call cuda_check_error(cudaEventRecord(start, 0))
    call vector_reduction_kernel<<<n_blocks, n_threads>>>(dev_values, n, dev_result)
    call cuda_check_error(cudaGetLastError())
    call cuda_check_error(cudaEventRecord(stop, 0))
    ! sync to check for errors
    call cuda_check_error(cudaDeviceSynchronize())
    gpu_result = dev_result
    ! sync to ensure copy is completed
    call cuda_check_error(cudaDeviceSynchronize())
    ! check the correctness of the result 
    if(gpu_result /= correct_result) then
        print *, "Error: result is incorrect!"
        stop
    end if
    print *, "Result is ", gpu_result
    call cuda_check_error(cudaEventElapsedTime(elapsed, start, stop))
    print '("Kernel execution time: ", f6.3, "(s)")', elapsed / 1000
    deallocate (dev_values, values)
    call cuda_check_error(cudaEventDestroy(start))
    call cuda_check_error(cudaEventDestroy(stop))
end program vector_reduction
